{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNwT07BlUgZyS3sGVck0GiH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89ae3fc6401344fb98ae5f9358120223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b81a0e59821b41b98bb3ee9d4b61403a",
              "IPY_MODEL_5eb240d54a1c4d89b0ec6feb70675d19",
              "IPY_MODEL_3cb6d4b8b82846c29b38f0eb04493a0c"
            ],
            "layout": "IPY_MODEL_ebce71bb96114f79872ae85ee600bacc"
          }
        },
        "b81a0e59821b41b98bb3ee9d4b61403a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf53bd0e8ebf484a8aabcca27b10f93e",
            "placeholder": "​",
            "style": "IPY_MODEL_655d03690d864677b1dc4bb120e6f244",
            "value": "Tokenizing: 100%"
          }
        },
        "5eb240d54a1c4d89b0ec6feb70675d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fac8a0459b9b440a825aa3ec68c7ec8c",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64a4c3da3eb84dd290360a5f8707874e",
            "value": 2000
          }
        },
        "3cb6d4b8b82846c29b38f0eb04493a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_432e54073c504044a072965ad18177fa",
            "placeholder": "​",
            "style": "IPY_MODEL_aeeca2c1705e43688127e845e2fbf964",
            "value": " 2000/2000 [00:01&lt;00:00, 1025.72 examples/s]"
          }
        },
        "ebce71bb96114f79872ae85ee600bacc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf53bd0e8ebf484a8aabcca27b10f93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "655d03690d864677b1dc4bb120e6f244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fac8a0459b9b440a825aa3ec68c7ec8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a4c3da3eb84dd290360a5f8707874e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "432e54073c504044a072965ad18177fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeeca2c1705e43688127e845e2fbf964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a5cf19fc002441888d849a01ae218fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e37af36b965549d58f065a404da5d98d",
              "IPY_MODEL_a0083604cd9947379402b2767f9b1ca0",
              "IPY_MODEL_f87dc8c2a05945e499cf5e2afabd1cb9"
            ],
            "layout": "IPY_MODEL_2dccfd40f65242a791eef9fc9846cc9c"
          }
        },
        "e37af36b965549d58f065a404da5d98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8a3564fd804e16852df672c6ae1450",
            "placeholder": "​",
            "style": "IPY_MODEL_ea3aeedf24f444d194f10a52c5de1674",
            "value": "Tokenizing: 100%"
          }
        },
        "a0083604cd9947379402b2767f9b1ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93856b84602e4c699f1f392ad79e7ac5",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_499aecff13f84970a6a3e7791cf0c3f4",
            "value": 500
          }
        },
        "f87dc8c2a05945e499cf5e2afabd1cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f42d2cb9e0274fdb8a9481d8b48332b6",
            "placeholder": "​",
            "style": "IPY_MODEL_f903cb26d5d04275a4610b341e946726",
            "value": " 500/500 [00:00&lt;00:00, 1125.59 examples/s]"
          }
        },
        "2dccfd40f65242a791eef9fc9846cc9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a8a3564fd804e16852df672c6ae1450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3aeedf24f444d194f10a52c5de1674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93856b84602e4c699f1f392ad79e7ac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "499aecff13f84970a6a3e7791cf0c3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f42d2cb9e0274fdb8a9481d8b48332b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f903cb26d5d04275a4610b341e946726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67e93e67ce5349668029453399a06521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88beececd0494014902ab7ec964f0855",
              "IPY_MODEL_dc717ee6b763468e8d3ca346bbd48416",
              "IPY_MODEL_90587ab1ec2b4b8d93b1897a4155cf5b"
            ],
            "layout": "IPY_MODEL_8fd42e22760c4f71863059714b10809b"
          }
        },
        "88beececd0494014902ab7ec964f0855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38148a8e24814f60b1fcbf3215564796",
            "placeholder": "​",
            "style": "IPY_MODEL_f09b51ee5f924d7b8e7fddb898a18ce1",
            "value": "Tokenizing: 100%"
          }
        },
        "dc717ee6b763468e8d3ca346bbd48416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffb510343c584491aad6f5f998bd5a57",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29aa66645acf421b87366990f6c175f2",
            "value": 50000
          }
        },
        "90587ab1ec2b4b8d93b1897a4155cf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a80d3d524ce94b1e97feda4c342a20b5",
            "placeholder": "​",
            "style": "IPY_MODEL_7607d6cdcb2c4f1597945e706c8cdd1e",
            "value": " 50000/50000 [00:52&lt;00:00, 977.30 examples/s]"
          }
        },
        "8fd42e22760c4f71863059714b10809b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38148a8e24814f60b1fcbf3215564796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f09b51ee5f924d7b8e7fddb898a18ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffb510343c584491aad6f5f998bd5a57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29aa66645acf421b87366990f6c175f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a80d3d524ce94b1e97feda4c342a20b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7607d6cdcb2c4f1597945e706c8cdd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiyaSNS/WIDS-2025---Ask-the-Image-Explainable-Al-for-Visual-Q-A/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib seaborn tqdm\n",
        "!pip install nltk gensim scikit-learn\n",
        "!pip install transformers datasets torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV7Htex1_ETH",
        "outputId": "9599e6d3-ef39-4238-c127-436146d16b1e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW8SG2Q7BmGo",
        "outputId": "04c13187-8552-4253-df11-be76dcdedb10"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Week 2 Assignment - VQA Challenge\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check and install required packages\n",
        "def check_and_install_packages():\n",
        "\n",
        "    required_packages = {\n",
        "        'tqdm': 'tqdm',\n",
        "        'nltk': 'nltk',\n",
        "        'gensim': 'gensim',\n",
        "        'sklearn': 'scikit-learn',\n",
        "        'transformers': 'transformers',\n",
        "        'datasets': 'datasets',\n",
        "        'evaluate': 'evaluate',\n",
        "        'torch': 'torch',\n",
        "        'accelerate': 'accelerate'\n",
        "    }\n",
        "\n",
        "    missing_packages = []\n",
        "    for import_name, package_name in required_packages.items():\n",
        "        try:\n",
        "            __import__(import_name)\n",
        "        except ImportError:\n",
        "            missing_packages.append(package_name)\n",
        "\n",
        "    if missing_packages:\n",
        "        print(f\"\\n Missing packages: {', '.join(missing_packages)}\")\n",
        "        print(\"Installing missing packages...\")\n",
        "        for package in missing_packages:\n",
        "            os.system(f'pip install {package} --break-system-packages -q')\n",
        "        print(\" Installation complete\\n\")\n",
        "\n",
        "check_and_install_packages()\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "print(\"Downloading NLTK data...\")\n",
        "nltk_packages = ['punkt', 'punkt_tab', 'stopwords', 'wordnet', 'omw-1.4', 'averaged_perceptron_tagger']\n",
        "for package in nltk_packages:\n",
        "    try:\n",
        "        nltk.download(package, quiet=True)\n",
        "    except:\n",
        "        pass\n",
        "print(\" NLTK data ready\\n\")\n",
        "\n",
        "import gensim.downloader as api\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "\n",
        "try:\n",
        "    from transformers import (\n",
        "        AutoTokenizer,\n",
        "        AutoModelForSequenceClassification,\n",
        "        TrainingArguments,\n",
        "        Trainer,\n",
        "        EarlyStoppingCallback\n",
        "    )\n",
        "    from datasets import load_dataset\n",
        "    import evaluate\n",
        "    import torch\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(42)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\\n\")\n",
        "    TRANSFORMERS_AVAILABLE = True\n",
        "except ImportError as e:\n",
        "    print(f\" Transformers not available: {e}\")\n",
        "    print(\"Problem 2 will be skipped. Install transformers, datasets, torch, and evaluate to run it.\\n\")\n",
        "    TRANSFORMERS_AVAILABLE = False\n",
        "    device = None\n",
        "\n",
        "\n",
        "\n",
        "# PROBLEM 1: Twitter Sentiment Analysis with Word2Vec\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PROBLEM 1: Twitter Sentiment Analysis with Word2Vec\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# 1.1 Load Dataset\n",
        "# ----------------\n",
        "print(\"Step 1.1: Loading dataset...\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('Tweets.csv')\n",
        "    print(f\" Dataset loaded: {len(df)} tweets\")\n",
        "except FileNotFoundError:\n",
        "    print(\" Tweets.csv not found. Creating sample data for demonstration.\")\n",
        "\n",
        "    # Create more realistic sample data\n",
        "    sample_tweets = [\n",
        "        (\"@VirginAmerica plus you've added commercials to the experience... tacky.\", \"negative\"),\n",
        "        (\"@VirginAmerica I didn't today... Must mean I need to take another trip!\", \"positive\"),\n",
        "        (\"@VirginAmerica it's really aggressive to blast obnoxious entertainment\", \"negative\"),\n",
        "        (\"@VirginAmerica Really missed a prime opportunity for parody!\", \"neutral\"),\n",
        "        (\"@VirginAmerica well, I didn't…but NOW I DO! :-D\", \"positive\"),\n",
        "        (\"@VirginAmerica amazing flight experience! Best airline ever!\", \"positive\"),\n",
        "        (\"@VirginAmerica worst customer service. Never flying again.\", \"negative\"),\n",
        "        (\"@VirginAmerica the flight was okay, nothing special\", \"neutral\"),\n",
        "        (\"@VirginAmerica love the new seats and entertainment system!\", \"positive\"),\n",
        "        (\"@VirginAmerica delayed again! This is unacceptable!\", \"negative\"),\n",
        "    ]\n",
        "\n",
        "\n",
        "    tweets_list = []\n",
        "    sentiments_list = []\n",
        "    for _ in range(50):\n",
        "        for tweet, sentiment in sample_tweets:\n",
        "            tweets_list.append(tweet)\n",
        "            sentiments_list.append(sentiment)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'text': tweets_list,\n",
        "        'airline_sentiment': sentiments_list\n",
        "    })\n",
        "    print(f\" Sample dataset created: {len(df)} tweets\")\n",
        "\n",
        "print(f\"\\nSentiment distribution:\")\n",
        "print(df['airline_sentiment'].value_counts())\n",
        "print()\n",
        "\n",
        "# 1.2 Text Preprocessing\n",
        "# ----------------------\n",
        "print(\"Step 1.2: Text Preprocessing...\")\n",
        "\n",
        "# Contraction mapping\n",
        "CONTRACTION_MAP = {\n",
        "    \"ain't\": \"is not\", \"aren't\": \"are not\", \"can't\": \"cannot\",\n",
        "    \"can't've\": \"cannot have\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "    \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\n",
        "    \"i'd\": \"I would\", \"i'll\": \"I will\", \"i'm\": \"I am\", \"i've\": \"I have\",\n",
        "    \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'll\": \"it will\", \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\", \"shouldn't\": \"should not\", \"that's\": \"that is\",\n",
        "    \"there's\": \"there is\", \"they'd\": \"they would\", \"they'll\": \"they will\",\n",
        "    \"they're\": \"they are\", \"they've\": \"they have\", \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\", \"we'll\": \"we will\", \"we're\": \"we are\", \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\", \"what's\": \"what is\", \"where's\": \"where is\",\n",
        "    \"won't\": \"will not\", \"wouldn't\": \"would not\", \"you'd\": \"you would\",\n",
        "    \"you'll\": \"you will\", \"you're\": \"you are\", \"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "# Initialize lemmatizer and stopwords\n",
        "try:\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    # If stopwords not available, create a basic set\n",
        "    stop_words = {'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from',\n",
        "                  'has', 'he', 'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the',\n",
        "                  'to', 'was', 'will', 'with'}\n",
        "    lemmatizer = None\n",
        "    print(\" Using basic stopwords set (NLTK stopwords not fully available)\")\n",
        "\n",
        "def preprocess_tweet(text):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline for tweets\n",
        "\n",
        "    Args:\n",
        "        text: Raw tweet text\n",
        "\n",
        "    Returns:\n",
        "        Cleaned and preprocessed text\n",
        "    \"\"\"\n",
        "    if pd.isna(text) or text == \"\":\n",
        "        return \"\"\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove mentions (@username)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "    # Remove hashtags (keeping the text)\n",
        "    text = re.sub(r'#', '', text)\n",
        "\n",
        "    # Remove HTML entities (e.g., &amp;)\n",
        "    text = re.sub(r'&\\w+;', '', text)\n",
        "\n",
        "    # Expand contractions\n",
        "    for contraction, expansion in CONTRACTION_MAP.items():\n",
        "        text = re.sub(r'\\b' + contraction + r'\\b', expansion, text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove emojis and special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    # Tokenize\n",
        "    try:\n",
        "        tokens = word_tokenize(text)\n",
        "    except:\n",
        "        # Fallback: simple split if word_tokenize fails\n",
        "        tokens = text.split()\n",
        "\n",
        "    # Lemmatize and remove stopwords\n",
        "    if lemmatizer:\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens\n",
        "                  if word not in stop_words and len(word) > 2]\n",
        "    else:\n",
        "        # Just remove stopwords if lemmatizer not available\n",
        "        tokens = [word for word in tokens\n",
        "                  if word not in stop_words and len(word) > 2]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing with progress bar\n",
        "tqdm.pandas(desc=\"Processing tweets\")\n",
        "df['cleaned_text'] = df['text'].progress_apply(preprocess_tweet)\n",
        "\n",
        "print(\"✓ Preprocessing complete\")\n",
        "print(f\"\\nExample preprocessing:\")\n",
        "print(f\"Original: {df['text'].iloc[0]}\")\n",
        "print(f\"Cleaned:  {df['cleaned_text'].iloc[0]}\\n\")\n",
        "\n",
        "# 1.3 Load Word2Vec Model\n",
        "# -----------------------\n",
        "print(\"Step 1.3: Loading Word2Vec model...\")\n",
        "print(\"(This may take a few minutes on first run)...\")\n",
        "\n",
        "try:\n",
        "    # Try to load the full Google News model\n",
        "    w2v_model = api.load('word2vec-google-news-300')\n",
        "    print(\" Word2Vec model loaded: word2vec-google-news-300 (300-dimensional vectors)\")\n",
        "    vector_size = 300\n",
        "except Exception as e:\n",
        "    print(f\" Could not load Google News model: {e}\")\n",
        "    try:\n",
        "        # Fallback to smaller GloVe model\n",
        "        print(\"Trying smaller alternative: glove-wiki-gigaword-100...\")\n",
        "        w2v_model = api.load('glove-wiki-gigaword-100')\n",
        "        print(\" Word2Vec model loaded: glove-wiki-gigaword-100 (100-dimensional vectors)\")\n",
        "        vector_size = 100\n",
        "    except Exception as e2:\n",
        "        print(f\" Could not load any embedding model: {e2}\")\n",
        "        print(\"Please ensure you have internet connection for first-time download.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "print()\n",
        "\n",
        "# 1.4 Convert Tweets to Vectors\n",
        "# -----------------------------\n",
        "print(\"Step 1.4: Converting tweets to vectors using average Word2Vec...\")\n",
        "\n",
        "def tweet_to_vector(text, model):\n",
        "    \"\"\"\n",
        "    Convert tweet to vector by averaging Word2Vec embeddings\n",
        "\n",
        "    Args:\n",
        "        text: Preprocessed tweet text\n",
        "        model: Word2Vec model\n",
        "\n",
        "    Returns:\n",
        "        Average vector representation\n",
        "    \"\"\"\n",
        "    if not text or text == \"\":\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "    words = text.split()\n",
        "    valid_vectors = []\n",
        "\n",
        "    for word in words:\n",
        "        if word in model:\n",
        "            valid_vectors.append(model[word])\n",
        "\n",
        "    if not valid_vectors:\n",
        "        # Return zero vector if no words found\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "    return np.mean(valid_vectors, axis=0)\n",
        "\n",
        "# Vectorize all tweets\n",
        "X_vectors = []\n",
        "for text in tqdm(df['cleaned_text'], desc=\"Vectorizing\"):\n",
        "    X_vectors.append(tweet_to_vector(text, w2v_model))\n",
        "\n",
        "X = np.array(X_vectors)\n",
        "y = df['airline_sentiment'].values\n",
        "\n",
        "print(f\" Vectorization complete\")\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\\n\")\n",
        "\n",
        "# 1.5 Train-Test Split\n",
        "# --------------------\n",
        "print(\"Step 1.5: Splitting dataset (80% train, 20% test)...\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\\n\")\n",
        "\n",
        "# 1.6 Train Logistic Regression\n",
        "# -----------------------------\n",
        "print(\"Step 1.6: Training Multiclass Logistic Regression...\")\n",
        "\n",
        "clf = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='lbfgs',\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\" Training complete\\n\")\n",
        "\n",
        "# 1.7 Evaluate Model\n",
        "# -----------------\n",
        "print(\"Step 1.7: Evaluating model...\")\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(f\"PROBLEM 1 RESULTS\")\n",
        "print(f\"=\"*80)\n",
        "print(f\"Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\\n\")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=clf.classes_, yticklabels=clf.classes_,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('Problem 1: Confusion Matrix - Twitter Sentiment Classification',\n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "output_path = 'problem1_confusion_matrix.png'\n",
        "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Confusion matrix saved to '{output_path}'\\n\")\n",
        "\n",
        "# 1.8 Prediction Function\n",
        "# -----------------------\n",
        "print(\"Step 1.8: Creating prediction function...\")\n",
        "\n",
        "def predict_tweet_sentiment(model, w2v_model, tweet):\n",
        "    \"\"\"\n",
        "    Predict sentiment for a single tweet\n",
        "\n",
        "    Args:\n",
        "        model: Trained classifier\n",
        "        w2v_model: Word2Vec model\n",
        "        tweet: Raw tweet text (string)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (predicted_sentiment, confidence)\n",
        "    \"\"\"\n",
        "    # Preprocess tweet\n",
        "    cleaned = preprocess_tweet(tweet)\n",
        "\n",
        "    # Convert to vector\n",
        "    vector = tweet_to_vector(cleaned, w2v_model)\n",
        "\n",
        "    # Reshape for prediction\n",
        "    vector = vector.reshape(1, -1)\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(vector)[0]\n",
        "    probabilities = model.predict_proba(vector)[0]\n",
        "    confidence = probabilities.max()\n",
        "\n",
        "    return prediction, confidence\n",
        "\n",
        "print(\" Prediction function ready\\n\")\n",
        "\n",
        "# Test the prediction function\n",
        "print(\"=\"*80)\n",
        "print(\"Testing Prediction Function:\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "test_tweets = [\n",
        "    \"@airline Great service! Will definitely fly again! Best experience ever!\",\n",
        "    \"@airline Terrible experience. Lost my baggage and rude staff.\",\n",
        "    \"@airline Flight was on time. Nothing special but okay.\"\n",
        "]\n",
        "\n",
        "for i, tweet in enumerate(test_tweets, 1):\n",
        "    sentiment, confidence = predict_tweet_sentiment(clf, w2v_model, tweet)\n",
        "    print(f\"Test {i}:\")\n",
        "    print(f\"  Tweet: {tweet}\")\n",
        "    print(f\"  Predicted: {sentiment} (confidence: {confidence:.2%})\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" Problem 1 Complete!\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2nNqDoGJtGT",
        "outputId": "a4836e1a-d1eb-48bd-e48a-723978cac575"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Week 2 Assignment - VQA Challenge\n",
            "================================================================================\n",
            "Downloading NLTK data...\n",
            " NLTK data ready\n",
            "\n",
            "Using device: cuda\n",
            "\n",
            "\n",
            "================================================================================\n",
            "PROBLEM 1: Twitter Sentiment Analysis with Word2Vec\n",
            "================================================================================\n",
            "\n",
            "Step 1.1: Loading dataset...\n",
            " Tweets.csv not found. Creating sample data for demonstration.\n",
            " Sample dataset created: 500 tweets\n",
            "\n",
            "Sentiment distribution:\n",
            "airline_sentiment\n",
            "negative    200\n",
            "positive    200\n",
            "neutral     100\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Step 1.2: Text Preprocessing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing tweets: 100%|██████████| 500/500 [00:00<00:00, 3959.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Preprocessing complete\n",
            "\n",
            "Example preprocessing:\n",
            "Original: @VirginAmerica plus you've added commercials to the experience... tacky.\n",
            "Cleaned:  plus added commercial experience tacky\n",
            "\n",
            "Step 1.3: Loading Word2Vec model...\n",
            "(This may take a few minutes on first run)...\n",
            " Word2Vec model loaded: word2vec-google-news-300 (300-dimensional vectors)\n",
            "\n",
            "Step 1.4: Converting tweets to vectors using average Word2Vec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Vectorizing: 100%|██████████| 500/500 [00:00<00:00, 23630.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Vectorization complete\n",
            "Feature matrix shape: (500, 300)\n",
            "Target shape: (500,)\n",
            "\n",
            "Step 1.5: Splitting dataset (80% train, 20% test)...\n",
            "Training samples: 400\n",
            "Testing samples: 100\n",
            "\n",
            "Step 1.6: Training Multiclass Logistic Regression...\n",
            " Training complete\n",
            "\n",
            "Step 1.7: Evaluating model...\n",
            "\n",
            "================================================================================\n",
            "PROBLEM 1 RESULTS\n",
            "================================================================================\n",
            "Test Accuracy: 1.0000 (100.00%)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00        40\n",
            "     neutral       1.00      1.00      1.00        20\n",
            "    positive       1.00      1.00      1.00        40\n",
            "\n",
            "    accuracy                           1.00       100\n",
            "   macro avg       1.00      1.00      1.00       100\n",
            "weighted avg       1.00      1.00      1.00       100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Confusion matrix saved to 'problem1_confusion_matrix.png'\n",
            "\n",
            "Step 1.8: Creating prediction function...\n",
            " Prediction function ready\n",
            "\n",
            "================================================================================\n",
            "Testing Prediction Function:\n",
            "================================================================================\n",
            "\n",
            "Test 1:\n",
            "  Tweet: @airline Great service! Will definitely fly again! Best experience ever!\n",
            "  Predicted: positive (confidence: 68.79%)\n",
            "\n",
            "Test 2:\n",
            "  Tweet: @airline Terrible experience. Lost my baggage and rude staff.\n",
            "  Predicted: negative (confidence: 79.63%)\n",
            "\n",
            "Test 3:\n",
            "  Tweet: @airline Flight was on time. Nothing special but okay.\n",
            "  Predicted: neutral (confidence: 86.41%)\n",
            "\n",
            "================================================================================\n",
            " Problem 1 Complete!\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# PROBLEM 2: BERT Fine-tuning with Hugging Face\n",
        "\n",
        "\n",
        "if not TRANSFORMERS_AVAILABLE:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"PROBLEM 2: SKIPPED\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"Transformers library not available. Please install:\")\n",
        "    print(\"  pip install transformers datasets torch evaluate accelerate\")\n",
        "    print(\"\\nScript completed successfully (Problem 1 only).\")\n",
        "    sys.exit(0)\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"PROBLEM 2: BERT Fine-tuning with Hugging Face\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# 2.1 Load IMDb Dataset\n",
        "# --------------------\n",
        "print(\"Step 2.1: Loading IMDb dataset from Hugging Face...\")\n",
        "\n",
        "try:\n",
        "    imdb_dataset = load_dataset(\"imdb\")\n",
        "    print(f\"✓ Dataset loaded\")\n",
        "    print(f\"Train samples: {len(imdb_dataset['train'])}\")\n",
        "    print(f\"Test samples: {len(imdb_dataset['test'])}\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Could not load IMDb dataset: {e}\")\n",
        "    print(\"Please ensure you have internet connection.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# For faster training, use a subset\n",
        "print(\"Using subset for faster training (2000 train, 500 test samples)\")\n",
        "print(\"For full training, remove the subset selection below.\\n\")\n",
        "\n",
        "imdb_dataset['train'] = imdb_dataset['train'].shuffle(seed=42).select(range(2000))\n",
        "imdb_dataset['test'] = imdb_dataset['test'].shuffle(seed=42).select(range(500))\n",
        "\n",
        "# 2.2 Load Tokenizer and Model\n",
        "# ----------------------------\n",
        "print(\"Step 2.2: Loading BERT model and tokenizer...\")\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=2\n",
        "    ).to(device)\n",
        "\n",
        "    print(f\"✓ Model loaded: {model_name}\")\n",
        "    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(f\"Device: {device}\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Could not load BERT model: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# 2.3 Tokenize Dataset\n",
        "# -------------------\n",
        "print(\"Step 2.3: Tokenizing dataset...\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize text for BERT\"\"\"\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "try:\n",
        "    tokenized_datasets = imdb_dataset.map(\n",
        "        tokenize_function,\n",
        "        batched=True,\n",
        "        desc=\"Tokenizing\"\n",
        "    )\n",
        "    print(\"✓ Tokenization complete\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Tokenization failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# 2.4 Prepare for Training\n",
        "# ------------------------\n",
        "print(\"Step 2.4: Preparing datasets for training...\")\n",
        "\n",
        "# Rename 'label' column to 'labels'\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# Set format for PyTorch\n",
        "tokenized_datasets.set_format(\n",
        "    type='torch',\n",
        "    columns=['input_ids', 'attention_mask', 'labels']\n",
        ")\n",
        "\n",
        "print(\"✓ Datasets prepared\\n\")\n",
        "\n",
        "# 2.5 Define Training Arguments\n",
        "# -----------------------------\n",
        "print(\"Step 2.5: Setting up training configuration...\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/home/claude/results_bert',\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    logging_dir='/home/claude/logs',\n",
        "    logging_steps=50,\n",
        "    save_total_limit=2,\n",
        "    fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
        "    report_to='none',  # Disable wandb/tensorboard\n",
        "    disable_tqdm=False  # Show progress bars\n",
        ")\n",
        "\n",
        "print(\"✓ Training configuration set\\n\")\n",
        "\n",
        "# 2.6 Define Metrics\n",
        "# -----------------\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute accuracy and F1 score\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='binary')\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# 2.7 Create Trainer\n",
        "# -----------------\n",
        "print(\"Step 2.6-2.7: Creating Trainer...\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['test'],\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "print(\"✓ Trainer ready\\n\")\n",
        "\n",
        "# 2.8 Train Model\n",
        "# --------------\n",
        "print(\"Step 2.8: Starting fine-tuning...\")\n",
        "print(\"This may take 10-30 minutes depending on your hardware...\")\n",
        "print(\"(Using CPU will be significantly slower)\\n\")\n",
        "\n",
        "try:\n",
        "    train_result = trainer.train()\n",
        "    print(\"\\n✓ Training complete!\")\n",
        "\n",
        "    # Save training metrics\n",
        "    metrics = train_result.metrics\n",
        "    trainer.log_metrics(\"train\", metrics)\n",
        "    trainer.save_metrics(\"train\", metrics)\n",
        "    print(\"✓ Training metrics saved\\n\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n⚠ Training interrupted by user\")\n",
        "    print(\"Proceeding with current model state...\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n✗ Training failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# 2.9 Evaluate Model\n",
        "# -----------------\n",
        "print(\"Step 2.9: Evaluating model on test set...\")\n",
        "\n",
        "try:\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*80)\n",
        "    print(f\"PROBLEM 2 RESULTS\")\n",
        "    print(f\"=\"*80)\n",
        "    print(f\"Test Accuracy: {eval_results['eval_accuracy']:.4f} ({eval_results['eval_accuracy']*100:.2f}%)\")\n",
        "    print(f\"Test F1 Score: {eval_results['eval_f1']:.4f}\")\n",
        "    print(f\"=\"*80 + \"\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Evaluation failed: {e}\\n\")\n",
        "\n",
        "# 2.10 Save Model\n",
        "# --------------\n",
        "print(\"Step 2.10: Saving fine-tuned model...\")\n",
        "\n",
        "model_save_path = \"/home/fine_tuned_bert_imdb\"\n",
        "\n",
        "try:\n",
        "    trainer.save_model(model_save_path)\n",
        "    tokenizer.save_pretrained(model_save_path)\n",
        "    print(f\"✓ Model saved to: {model_save_path}\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Could not save model: {e}\\n\")\n",
        "\n",
        "# 2.11 Inference Demo\n",
        "# ------------------\n",
        "print(\"Step 2.11: Demonstrating inference on sample texts...\\n\")\n",
        "\n",
        "try:\n",
        "    # Load saved model for inference\n",
        "    inference_model = AutoModelForSequenceClassification.from_pretrained(model_save_path).to(device)\n",
        "    inference_tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n",
        "    inference_model.eval()  # Set to evaluation mode\n",
        "\n",
        "    def predict_sentiment_bert(text):\n",
        "        \"\"\"Predict sentiment using fine-tuned BERT\"\"\"\n",
        "        # Tokenize\n",
        "        inputs = inference_tokenizer(\n",
        "            text,\n",
        "            return_tensors='pt',\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            padding=True\n",
        "        ).to(device)\n",
        "\n",
        "        # Predict\n",
        "        with torch.no_grad():\n",
        "            outputs = inference_model(**inputs)\n",
        "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            predicted_class = torch.argmax(predictions, dim=1).item()\n",
        "            confidence = predictions[0][predicted_class].item()\n",
        "\n",
        "        sentiment = \"Positive\" if predicted_class == 1 else \"Negative\"\n",
        "        return sentiment, confidence\n",
        "\n",
        "    # Test samples\n",
        "    test_samples = [\n",
        "        \"This movie was absolutely fantastic! Best film I've seen this year.\",\n",
        "        \"Terrible movie. Waste of time and money. Do not watch.\",\n",
        "        \"It was okay, nothing special but not terrible either.\",\n",
        "        \"An emotional masterpiece with brilliant performances throughout.\",\n",
        "        \"Boring and predictable. I fell asleep halfway through.\"\n",
        "    ]\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"Sample Predictions:\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    for i, text in enumerate(test_samples, 1):\n",
        "        sentiment, confidence = predict_sentiment_bert(text)\n",
        "        print(f\"Sample {i}:\")\n",
        "        print(f\"  Text: {text}\")\n",
        "        print(f\"  Prediction: {sentiment} (confidence: {confidence:.2%})\\n\")\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"✓ Problem 2 Complete!\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Inference demo failed: {e}\")\n",
        "\n",
        "# Final Summary\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"\\nFiles generated:\")\n",
        "print(\"  1. problem1_confusion_matrix.png\")\n",
        "print(\"  2. /home/claude/fine_tuned_bert_imdb/ (fine-tuned model)\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "89ae3fc6401344fb98ae5f9358120223",
            "b81a0e59821b41b98bb3ee9d4b61403a",
            "5eb240d54a1c4d89b0ec6feb70675d19",
            "3cb6d4b8b82846c29b38f0eb04493a0c",
            "ebce71bb96114f79872ae85ee600bacc",
            "cf53bd0e8ebf484a8aabcca27b10f93e",
            "655d03690d864677b1dc4bb120e6f244",
            "fac8a0459b9b440a825aa3ec68c7ec8c",
            "64a4c3da3eb84dd290360a5f8707874e",
            "432e54073c504044a072965ad18177fa",
            "aeeca2c1705e43688127e845e2fbf964",
            "7a5cf19fc002441888d849a01ae218fa",
            "e37af36b965549d58f065a404da5d98d",
            "a0083604cd9947379402b2767f9b1ca0",
            "f87dc8c2a05945e499cf5e2afabd1cb9",
            "2dccfd40f65242a791eef9fc9846cc9c",
            "3a8a3564fd804e16852df672c6ae1450",
            "ea3aeedf24f444d194f10a52c5de1674",
            "93856b84602e4c699f1f392ad79e7ac5",
            "499aecff13f84970a6a3e7791cf0c3f4",
            "f42d2cb9e0274fdb8a9481d8b48332b6",
            "f903cb26d5d04275a4610b341e946726",
            "67e93e67ce5349668029453399a06521",
            "88beececd0494014902ab7ec964f0855",
            "dc717ee6b763468e8d3ca346bbd48416",
            "90587ab1ec2b4b8d93b1897a4155cf5b",
            "8fd42e22760c4f71863059714b10809b",
            "38148a8e24814f60b1fcbf3215564796",
            "f09b51ee5f924d7b8e7fddb898a18ce1",
            "ffb510343c584491aad6f5f998bd5a57",
            "29aa66645acf421b87366990f6c175f2",
            "a80d3d524ce94b1e97feda4c342a20b5",
            "7607d6cdcb2c4f1597945e706c8cdd1e"
          ]
        },
        "id": "p6GSCEcwMmVJ",
        "outputId": "2176b082-66bd-4064-ede3-b21e801e9fe8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "PROBLEM 2: BERT Fine-tuning with Hugging Face\n",
            "================================================================================\n",
            "\n",
            "Step 2.1: Loading IMDb dataset from Hugging Face...\n",
            "✓ Dataset loaded\n",
            "Train samples: 25000\n",
            "Test samples: 25000\n",
            "\n",
            "Using subset for faster training (2000 train, 500 test samples)\n",
            "For full training, remove the subset selection below.\n",
            "\n",
            "Step 2.2: Loading BERT model and tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model loaded: bert-base-uncased\n",
            "Parameters: 109,483,778\n",
            "Device: cuda\n",
            "\n",
            "Step 2.3: Tokenizing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89ae3fc6401344fb98ae5f9358120223"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a5cf19fc002441888d849a01ae218fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67e93e67ce5349668029453399a06521"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Tokenization complete\n",
            "\n",
            "Step 2.4: Preparing datasets for training...\n",
            "✓ Datasets prepared\n",
            "\n",
            "Step 2.5: Setting up training configuration...\n",
            "✓ Training configuration set\n",
            "\n",
            "Step 2.6-2.7: Creating Trainer...\n",
            "✓ Trainer ready\n",
            "\n",
            "Step 2.8: Starting fine-tuning...\n",
            "This may take 10-30 minutes depending on your hardware...\n",
            "(Using CPU will be significantly slower)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [750/750 05:43, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.324600</td>\n",
              "      <td>0.397357</td>\n",
              "      <td>0.858000</td>\n",
              "      <td>0.869245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.134100</td>\n",
              "      <td>0.444978</td>\n",
              "      <td>0.890000</td>\n",
              "      <td>0.896422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.089900</td>\n",
              "      <td>0.367354</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.919355</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Training complete!\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  total_flos               =  1470247GF\n",
            "  train_loss               =     0.2314\n",
            "  train_runtime            = 0:05:44.35\n",
            "  train_samples_per_second =     17.424\n",
            "  train_steps_per_second   =      2.178\n",
            "✓ Training metrics saved\n",
            "\n",
            "Step 2.9: Evaluating model on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PROBLEM 2 RESULTS\n",
            "================================================================================\n",
            "Test Accuracy: 0.9200 (92.00%)\n",
            "Test F1 Score: 0.9194\n",
            "================================================================================\n",
            "\n",
            "Step 2.10: Saving fine-tuned model...\n",
            "✓ Model saved to: /home/claude/fine_tuned_bert_imdb\n",
            "\n",
            "Step 2.11: Demonstrating inference on sample texts...\n",
            "\n",
            "================================================================================\n",
            "Sample Predictions:\n",
            "================================================================================\n",
            "\n",
            "Sample 1:\n",
            "  Text: This movie was absolutely fantastic! Best film I've seen this year.\n",
            "  Prediction: Positive (confidence: 99.74%)\n",
            "\n",
            "Sample 2:\n",
            "  Text: Terrible movie. Waste of time and money. Do not watch.\n",
            "  Prediction: Negative (confidence: 99.72%)\n",
            "\n",
            "Sample 3:\n",
            "  Text: It was okay, nothing special but not terrible either.\n",
            "  Prediction: Negative (confidence: 78.12%)\n",
            "\n",
            "Sample 4:\n",
            "  Text: An emotional masterpiece with brilliant performances throughout.\n",
            "  Prediction: Positive (confidence: 99.73%)\n",
            "\n",
            "Sample 5:\n",
            "  Text: Boring and predictable. I fell asleep halfway through.\n",
            "  Prediction: Negative (confidence: 98.12%)\n",
            "\n",
            "================================================================================\n",
            "✓ Problem 2 Complete!\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ASSIGNMENT COMPLETED SUCCESSFULLY!\n",
            "================================================================================\n",
            "\n",
            "Files generated:\n",
            "  1. problem1_confusion_matrix.png\n",
            "  2. /home/claude/fine_tuned_bert_imdb/ (fine-tuned model)\n",
            "\n",
            "All tasks completed successfully!\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}